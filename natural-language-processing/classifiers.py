# -*- coding: utf-8 -*-
"""lista3-pln.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FoOtVQ8Qf-ni_Vnjg_uXjXHpcESwmcmg

**Lista 3**

*João Pedro Nunes & Yanka Ribeiro*

[**> preprocessed dataset <**](https://gist.github.com/yrribeiro/cfa3496bbe346743cd071380f1946f28)
"""

import random
import pandas as pd
import seaborn as sns
import numpy as np
import nltk
from itertools import combinations
from sklearn import preprocessing
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier

nltk.download('punkt')

filename = ''tweets_preproc.csv''

df = pd.read_csv(filename).drop_duplicates(subset=['text'])
txt_column = df['text']

"""**Questão 1**: Escolha 10 documentos da base, e determine seu documento mais parecido (que não pode ser ele mesmo), usando:

**a)** Representação vetorial CountVectorizer com similaridade do 
cosseno

---

"""

# escolhendo aleatoriamente 10 documentos da base
# corpus = random.choices(txt_column, k=10) -- feito anteriormente, exemplos foram escolhidos manualmente para a melhor visualização de similaridade
corpus = [
  'ke tla cheka harddrive at home pc crashed phone dead so you just hoping for miracles brother',
  'did i crash at pm yesterday and woke up just now',
  'its important to uphold the most righteous action not just something akin to islam or that doesnt contra'
  'minago earthquake has hit canas barrio ponce puerto rico mi am ast rspr',
  'earthquakes in puerto rico in the last days the earth keeps shaking families are sleeping on the st',
  'it isnt racism is a sad fact of life your difference will be exploited by ignora',
  'i learnt my trade here bl back then i can see at least of my old offices workshops in this photo sad to see it g',
  'hachisan leon and claire they fight bioterrorism and have busy days thats why they value the time they spend'	,
  'usmexico border portal for tb swine flu bioterrorism via',
  'this comment section is fucking cancer this laila person is probably wrong vaushs point was misunderstoo',
]

# criando um countvectorizer e uma matriz esparsa representando as sentenças
cv = CountVectorizer(stop_words='english')
array = cv.fit_transform(corpus).toarray()
pd.DataFrame(array, columns=cv.get_feature_names_out())

# função para plotar o dataframe com os os valores de similaridade, para melhor visualização
def create_dataframe(matrix, tokens):
    doc_names = [f'{tokens[i]}' for i, _ in enumerate(matrix)]
    df = pd.DataFrame(data=matrix, index=doc_names, columns=tokens)
    return df

# calculando a similaridade por coseno entre sentenças do array
cosine_similarity_matrix = cosine_similarity(array)
results = create_dataframe(cosine_similarity_matrix, corpus)
results

"""**a)** Representação vetorial TF-IDF com similaridade do cosseno

---


"""

# criando um vetorizador TF IDF
cv_tf = TfidfVectorizer(stop_words='english')
array_tf = cv_tf.fit_transform(corpus).toarray()
pd.DataFrame(array_tf, columns=cv_tf.get_feature_names_out())

# calculando a similaridade por coseno entre sentenças do array
cosine_similarity_matrix = cosine_similarity(array_tf)
results = create_dataframe(cosine_similarity_matrix, corpus)
results

"""**Questão 2**: Elabore um problema de classificação binária de textos coerente com sua base.

**a)** Determine o rótulo dos documentos (separando os documentos em classes bem definidas)

---

*1.   Com base na classe mais frequente, determinar se o tweet é sobre esse desastre ou não.*
"""

# o dataset já está rotulado, com 141 classes (após o pré-processamento, antes = 219), e uma coluna específica (target) para rotulamento
labelEnc = preprocessing.LabelEncoder()
encoded_keywords = labelEnc.fit_transform(df['keyword'])
print(len(list(labelEnc.classes_)))
labels = list(labelEnc.classes_)
labels

# criando um ranking de top_N tipos de desastres mais comuns no dataframe
def create_ranking(df):
  top_N = 10
  keywords = df.keyword.str.replace(r'%20', ' ').str.cat(sep=' ')
  words = nltk.tokenize.word_tokenize(keywords)
  word_dist = nltk.FreqDist(words)
  result = pd.DataFrame(word_dist.most_common(top_N), columns=['Type of disaster', 'Frequency'])
  result['% over the dataframe'] = round((result['Frequency']/len(df.index))*100, 2) # porcentagem = disastre/total de tweets
  return result

result = create_ranking(df)
result

"""Aqui, o desastre mais comum é do tipo 'emergency'. Na lista de keywords acima podemos ver que existem outras subclasses dentro de 'emergency', exemplo: 'emergency%20plan', o ranking já faz o agrupamento de todas as subclasses na hora de calcular a frequência. Portanto, 'emergency' aparece em 1° lugar devido a soma de frequência de suas subclasses.

'emergency%20plan' + 'emergency%20services' + 'emergency' = 214
"""

# criando uma nova coluna no dataset para anotar se o tweet é sobre emergency ou não
new_df = df
new_df['emergency_target'] = np.where(new_df['keyword'].str.contains('emergency'), 1, 0)
new_df

"""**b)** Extraia as representações vetoriais com CountVectorizer e TF-IDF

---


"""

# CountVectorizer dos tweets sobre emergência
emergency = df.loc[df['keyword'] == 'emergency']['text']
emergency_array = cv.fit_transform(emergency).toarray()
pd.DataFrame(emergency_array, columns=cv.get_feature_names_out())

# TF-IDF
emergency_tf_array = cv_tf.fit_transform(emergency).toarray()
pd.DataFrame(emergency_tf_array, columns=cv_tf.get_feature_names_out())

"""**c)** Treine um classificador baseado em cada uma das duas representações vetoriais e Regressão Logística usando validação cruzada com 70% das amostras selecionadas para treino e 30% para teste. Exiba as matrizes de confusão, métricas de acurácia, precis̃ao, recall e F1 score

---


"""

# CountVectorizer
X = cv.fit_transform(new_df['text'].values)
y = new_df['emergency_target']
lr = LogisticRegression()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

lr.fit(X_train, y_train)

# usando o modelo treinado
y_pred = lr.predict(X_test)
y_pred.shape

# mostrando métricas
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(
    cm, 
    xticklabels = ['predicted_not_emgcy', 'predicted_emgcy'],
    yticklabels = ['real_not_emgcy', 'real_emgcy'],
    annot=True,
    fmt='d',
    annot_kws = {'fontsize':20},
    cmap = 'inferno',

)

all_accuracies, all_precisions, all_recalls, all_f1 = [], [], [], []
def print_classification_report(y_test, y_pred):
  target_names = ['AN EMERGENCY', 'NOT AN EMERGENCY']
  return classification_report(y_test, y_pred, target_names=target_names, output_dict=True, digits=2, zero_division=1)

df_cv_lr = pd.DataFrame(print_classification_report(y_test, y_pred)).drop(axis=0, labels=['support'])
all_accuracies.append(df_cv_lr['accuracy'][0])
all_precisions.append(df_cv_lr['macro avg'][0])
all_recalls.append(df_cv_lr['macro avg'][1])
all_f1.append(df_cv_lr['macro avg'][2])
df_cv_lr

# TF-IDF
X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(X, y, test_size=0.3, random_state=42)
model_tf = lr.fit(X_train_tf, y_train_tf)

# usando o modelo treinado
y_pred_tf = lr.predict(X_test_tf)
y_pred_tf.shape

# mostrando métricas
cm = confusion_matrix(y_test_tf, y_pred_tf)
sns.heatmap(
    cm, 
    xticklabels = ['predicted_not_emgcy', 'predicted_emgcy'],
    yticklabels = ['real_not_emgcy', 'real_emgcy'],
    annot=True,
    fmt='d',
    annot_kws = {'fontsize':20},
    cmap = 'YlGnBu',
)

df_tf_lr = pd.DataFrame(print_classification_report(y_test_tf, y_pred_tf)).drop(axis=0, labels=['support'])
all_accuracies.append(df_tf_lr['accuracy'][0])
all_precisions.append(df_tf_lr['macro avg'][0])
all_recalls.append(df_tf_lr['macro avg'][1])
all_f1.append(df_tf_lr['macro avg'][2])
df_tf_lr

"""**d)** Faça o mesmo para o classificador Naive-Bayes

---


"""

# CountVectorizer
nb = MultinomialNB()
nb.fit(X_train, y_train)
y_pred_cv_nb = nb.predict(X_test)
y_pred_cv_nb.shape

# mostrando métricas
cm = confusion_matrix(y_test, y_pred_cv_nb)
sns.heatmap(
    cm, 
    xticklabels = ['predicted_not_emgcy', 'predicted_emgcy'],
    yticklabels = ['real_not_emgcy', 'real_emgcy'],
    annot=True,
    fmt='d',
    annot_kws = {'fontsize':20},
    cmap = 'Greys_r',
)

df_cv_nb = pd.DataFrame(print_classification_report(y_test, y_pred_cv_nb)).drop(axis=0, labels=['support'])
all_accuracies.append(df_cv_nb['accuracy'][0])
all_precisions.append(df_cv_nb['macro avg'][0])
all_recalls.append(df_cv_nb['macro avg'][1])
all_f1.append(df_cv_nb['macro avg'][2])
df_cv_nb

# TF-IDF
nb.fit(X_train_tf, y_train_tf)
y_pred_tf_nb = nb.predict(X_test_tf)
y_pred_tf_nb.shape

# mostrando métricas
import matplotlib.pyplot as plt
cm = confusion_matrix(y_test_tf, y_pred_tf_nb)
sns.heatmap(
    cm, 
    xticklabels = ['predicted_not_emgcy', 'predicted_emgcy'],
    yticklabels = ['real_not_emgcy', 'real_emgcy'],
    annot=True,
    fmt='d',
    annot_kws = {'fontsize':20},
    cmap = 'Greys',
)

df_tf_nb = pd.DataFrame(print_classification_report(y_test_tf, y_pred_tf_nb)).drop(axis=0, labels=['support'])
all_accuracies.append(df_tf_nb['accuracy'][0])
all_precisions.append(df_tf_nb['macro avg'][0])
all_recalls.append(df_tf_nb['macro avg'][1])
all_f1.append(df_tf_nb['macro avg'][2])
df_tf_nb

"""**e)** Faça o mesmo para um outro classificador de sua preferência (pesquise na biblioteca Scikit-learn)

---


"""

# Classificador escolhido: DECISION TREE
# CountVectorizer
clf = DecisionTreeClassifier(random_state=0)
# cross_val_score(clf, X_train, y_train, cv=3)
clf.fit(X_train, y_train)
y_pred_cv_dt = clf.predict(X_test)

# mostrando métricas
cm = confusion_matrix(y_test, y_pred_cv_dt)
sns.heatmap(
    cm, 
    xticklabels = ['predicted_not_emgcy', 'predicted_emgcy'],
    yticklabels = ['real_not_emgcy', 'real_emgcy'],
    annot=True,
    fmt='d',
    annot_kws = {'fontsize':20},
    cmap = 'YlGn_r',
)

df_cv_dt = pd.DataFrame(print_classification_report(y_test, y_pred_cv_dt)).drop(axis=0, labels=['support'])
all_accuracies.append(df_cv_dt['accuracy'][0])
all_precisions.append(df_cv_dt['macro avg'][0])
all_recalls.append(df_cv_dt['macro avg'][1])
all_f1.append(df_cv_dt['macro avg'][2])
df_cv_dt

# TF-IDF
clf.fit(X_train_tf, y_train_tf)
y_pred_tf_dt = clf.predict(X_test_tf)

cm = confusion_matrix(y_test_tf, y_pred_tf_dt)
sns.heatmap(
    cm, 
    xticklabels = ['predicted_not_emgcy', 'predicted_emgcy'],
    yticklabels = ['real_not_emgcy', 'real_emgcy'],
    annot=True,
    fmt='d',
    annot_kws = {'fontsize':20},
    cmap = 'YlGn',
)

df_tf_dt = pd.DataFrame(print_classification_report(y_test_tf, y_pred_tf_dt)).drop(axis=0, labels=['support'])
all_accuracies.append(df_tf_dt['accuracy'][0])
all_precisions.append(df_tf_dt['macro avg'][0])
all_recalls.append(df_tf_dt['macro avg'][1])
all_f1.append(df_tf_dt['macro avg'][2])
df_tf_dt

"""**f)** Compare os 6 resultados

---


"""

data = {
    'accuracy': all_accuracies,
    'precision': all_precisions,
    'recall': all_recalls,
    'f1-score': all_f1,
}
model_names = ['CV_LogisticRegression', 'TF_LogisticRegression', 'CV_NaiveBayes', 'TF_NaiveBayes', 'CV_DecisionTree', 'TF_DecisionTree']
data = pd.DataFrame(data)
data['model_names'] = model_names
data

data.plot(x='model_names', y=metric_names, subplots=True, kind='line', figsize=(16, 9), sharex=True)

"""Não houve diferença entre os vetorizadores.

1. Regressão logística: **Melhor acurácia** (98,4%) e **Melhor precisão** (93,7%)

2. Naive Bayes: pior desempenho em todas as métricas

3. Decision Tree: **Melhor recall** (84,4%) e **Melhor F1-Score** (86,8%)


"""