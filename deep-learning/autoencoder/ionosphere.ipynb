{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "DATA_PATH = 'ionosphere.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 34) (351,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83508</td>\n",
       "      <td>0.08298</td>\n",
       "      <td>0.73739</td>\n",
       "      <td>-0.14706</td>\n",
       "      <td>0.84349</td>\n",
       "      <td>-0.05567</td>\n",
       "      <td>0.90441</td>\n",
       "      <td>-0.04622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04202</td>\n",
       "      <td>0.83479</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.12815</td>\n",
       "      <td>0.86660</td>\n",
       "      <td>-0.10714</td>\n",
       "      <td>0.90546</td>\n",
       "      <td>-0.04307</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95113</td>\n",
       "      <td>0.00419</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>-0.02723</td>\n",
       "      <td>0.93438</td>\n",
       "      <td>-0.01920</td>\n",
       "      <td>0.94590</td>\n",
       "      <td>0.01606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01361</td>\n",
       "      <td>0.93522</td>\n",
       "      <td>0.04925</td>\n",
       "      <td>0.93159</td>\n",
       "      <td>0.08168</td>\n",
       "      <td>0.94066</td>\n",
       "      <td>-0.00035</td>\n",
       "      <td>0.91483</td>\n",
       "      <td>0.04712</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94701</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>0.93207</td>\n",
       "      <td>-0.03227</td>\n",
       "      <td>0.95177</td>\n",
       "      <td>-0.03431</td>\n",
       "      <td>0.95584</td>\n",
       "      <td>0.02446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>0.92489</td>\n",
       "      <td>0.02542</td>\n",
       "      <td>0.92120</td>\n",
       "      <td>0.02242</td>\n",
       "      <td>0.92459</td>\n",
       "      <td>0.00442</td>\n",
       "      <td>0.92697</td>\n",
       "      <td>-0.00577</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90608</td>\n",
       "      <td>-0.01657</td>\n",
       "      <td>0.98122</td>\n",
       "      <td>-0.01989</td>\n",
       "      <td>0.95691</td>\n",
       "      <td>-0.03646</td>\n",
       "      <td>0.85746</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02099</td>\n",
       "      <td>0.89147</td>\n",
       "      <td>-0.07760</td>\n",
       "      <td>0.82983</td>\n",
       "      <td>-0.17238</td>\n",
       "      <td>0.96022</td>\n",
       "      <td>-0.03757</td>\n",
       "      <td>0.87403</td>\n",
       "      <td>-0.16243</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84710</td>\n",
       "      <td>0.13533</td>\n",
       "      <td>0.73638</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>0.87873</td>\n",
       "      <td>0.08260</td>\n",
       "      <td>0.88928</td>\n",
       "      <td>-0.09139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15114</td>\n",
       "      <td>0.81147</td>\n",
       "      <td>-0.04822</td>\n",
       "      <td>0.78207</td>\n",
       "      <td>-0.00703</td>\n",
       "      <td>0.75747</td>\n",
       "      <td>-0.06678</td>\n",
       "      <td>0.85764</td>\n",
       "      <td>-0.06151</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1        2        3        4        5        6        7        8    \n",
       "0     1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000  \\\n",
       "1     1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2     1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "3     1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "4     1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "..   ..  ..      ...      ...      ...      ...      ...      ...      ...   \n",
       "346   1   0  0.83508  0.08298  0.73739 -0.14706  0.84349 -0.05567  0.90441   \n",
       "347   1   0  0.95113  0.00419  0.95183 -0.02723  0.93438 -0.01920  0.94590   \n",
       "348   1   0  0.94701 -0.00034  0.93207 -0.03227  0.95177 -0.03431  0.95584   \n",
       "349   1   0  0.90608 -0.01657  0.98122 -0.01989  0.95691 -0.03646  0.85746   \n",
       "350   1   0  0.84710  0.13533  0.73638 -0.06151  0.87873  0.08260  0.88928   \n",
       "\n",
       "          9   ...       25       26       27       28       29       30   \n",
       "0    0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267  \\\n",
       "1   -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "2    0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "3    0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "4   -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "..       ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "346 -0.04622  ... -0.04202  0.83479  0.00123  1.00000  0.12815  0.86660   \n",
       "347  0.01606  ...  0.01361  0.93522  0.04925  0.93159  0.08168  0.94066   \n",
       "348  0.02446  ...  0.03193  0.92489  0.02542  0.92120  0.02242  0.92459   \n",
       "349  0.00110  ... -0.02099  0.89147 -0.07760  0.82983 -0.17238  0.96022   \n",
       "350 -0.09139  ... -0.15114  0.81147 -0.04822  0.78207 -0.00703  0.75747   \n",
       "\n",
       "          31       32       33  34  \n",
       "0   -0.54487  0.18641 -0.45300   g  \n",
       "1   -0.06288 -0.13738 -0.02447   b  \n",
       "2   -0.24180  0.56045 -0.38238   g  \n",
       "3    1.00000 -0.32382  1.00000   b  \n",
       "4   -0.59573 -0.04608 -0.65697   g  \n",
       "..       ...      ...      ...  ..  \n",
       "346 -0.10714  0.90546 -0.04307   g  \n",
       "347 -0.00035  0.91483  0.04712   g  \n",
       "348  0.00442  0.92697 -0.00577   g  \n",
       "349 -0.03757  0.87403 -0.16243   g  \n",
       "350 -0.06678  0.85764 -0.06151   g  \n",
       "\n",
       "[351 rows x 35 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH, header=None)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].replace({\"b\": 0, \"g\": 1}).values\n",
    "print(X.shape, y.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "hidden_dim = 16\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "hidden_layer = Dense(hidden_dim, activation='relu')(input_layer)\n",
    "output_layer = Dense(input_dim, activation='linear')(hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.8949 - val_loss: 1.1217\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7924 - val_loss: 1.0107\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7104 - val_loss: 0.9208\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6443 - val_loss: 0.8492\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5899 - val_loss: 0.7859\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5456 - val_loss: 0.7251\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5044 - val_loss: 0.6722\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4693 - val_loss: 0.6270\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4375 - val_loss: 0.5833\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.4086 - val_loss: 0.5436\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.3829 - val_loss: 0.5068\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.3593 - val_loss: 0.4750\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3378 - val_loss: 0.4470\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3183 - val_loss: 0.4212\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.3009 - val_loss: 0.3926\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2847 - val_loss: 0.3675\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2701 - val_loss: 0.3451\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2562 - val_loss: 0.3265\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2445 - val_loss: 0.3061\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2333 - val_loss: 0.2865\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2227 - val_loss: 0.2737\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2137 - val_loss: 0.2587\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2047 - val_loss: 0.2453\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1968 - val_loss: 0.2332\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1895 - val_loss: 0.2213\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1829 - val_loss: 0.2095\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1767 - val_loss: 0.2002\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1710 - val_loss: 0.1909\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1655 - val_loss: 0.1833\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1606 - val_loss: 0.1749\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1561 - val_loss: 0.1673\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 0.1616\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1477 - val_loss: 0.1552\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1437 - val_loss: 0.1504\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1402 - val_loss: 0.1440\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1367 - val_loss: 0.1393\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1337 - val_loss: 0.1347\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1307 - val_loss: 0.1310\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1278 - val_loss: 0.1258\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1248 - val_loss: 0.1229\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1225 - val_loss: 0.1198\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1198 - val_loss: 0.1157\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1172 - val_loss: 0.1123\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1149 - val_loss: 0.1095\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1127 - val_loss: 0.1068\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1106 - val_loss: 0.1043\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1085 - val_loss: 0.1014\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1066 - val_loss: 0.0992\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1047 - val_loss: 0.0972\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1029 - val_loss: 0.0944\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1013 - val_loss: 0.0931\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0996 - val_loss: 0.0905\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0981 - val_loss: 0.0885\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0965 - val_loss: 0.0866\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0951 - val_loss: 0.0857\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0935 - val_loss: 0.0829\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0923 - val_loss: 0.0808\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0912 - val_loss: 0.0793\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0896 - val_loss: 0.0784\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0885 - val_loss: 0.0768\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0871 - val_loss: 0.0757\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0859 - val_loss: 0.0744\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0847 - val_loss: 0.0736\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0836 - val_loss: 0.0720\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0826 - val_loss: 0.0698\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0815 - val_loss: 0.0690\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0805 - val_loss: 0.0682\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0795 - val_loss: 0.0659\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0783 - val_loss: 0.0657\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0775 - val_loss: 0.0644\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0764 - val_loss: 0.0635\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0755 - val_loss: 0.0626\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0616\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.0736 - val_loss: 0.0609\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0728 - val_loss: 0.0601\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0720 - val_loss: 0.0581\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0711 - val_loss: 0.0572\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0704 - val_loss: 0.0556\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0695 - val_loss: 0.0562\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0687 - val_loss: 0.0565\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0679 - val_loss: 0.0549\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0672 - val_loss: 0.0542\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0667 - val_loss: 0.0535\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0657 - val_loss: 0.0520\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.0516\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0643 - val_loss: 0.0507\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0636 - val_loss: 0.0505\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0630 - val_loss: 0.0498\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0623 - val_loss: 0.0493\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0617 - val_loss: 0.0482\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0611 - val_loss: 0.0479\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0605 - val_loss: 0.0471\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0466\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0464\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0460\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0453\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0445\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0570 - val_loss: 0.0442\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0564 - val_loss: 0.0444\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.0559 - val_loss: 0.0428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2fe5808970>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = Model(input_layer, output_layer)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.fit(X, y, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 771us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288854</td>\n",
       "      <td>0.862737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629075</td>\n",
       "      <td>0.049585</td>\n",
       "      <td>0.764573</td>\n",
       "      <td>1.375301</td>\n",
       "      <td>0.471335</td>\n",
       "      <td>0.681091</td>\n",
       "      <td>1.029427</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.839820</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.745873</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223596</td>\n",
       "      <td>0.302742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.253786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376736</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.243774</td>\n",
       "      <td>1.103610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403095</td>\n",
       "      <td>0.909669</td>\n",
       "      <td>0.143316</td>\n",
       "      <td>1.018479</td>\n",
       "      <td>1.559943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.114099</td>\n",
       "      <td>1.181056</td>\n",
       "      <td>0.179748</td>\n",
       "      <td>0.988379</td>\n",
       "      <td>0.178192</td>\n",
       "      <td>0.117773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.492079</td>\n",
       "      <td>0.310226</td>\n",
       "      <td>0.288571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098349</td>\n",
       "      <td>0.315610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.455245</td>\n",
       "      <td>0.454553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.703830</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.882840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008051</td>\n",
       "      <td>0.582778</td>\n",
       "      <td>0.392145</td>\n",
       "      <td>0.545081</td>\n",
       "      <td>1.296126</td>\n",
       "      <td>0.912341</td>\n",
       "      <td>0.597561</td>\n",
       "      <td>1.145532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.829006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0.467792</td>\n",
       "      <td>0.817063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201966</td>\n",
       "      <td>1.011639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.043949</td>\n",
       "      <td>1.210953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.917380</td>\n",
       "      <td>0.831662</td>\n",
       "      <td>0.492514</td>\n",
       "      <td>0.604221</td>\n",
       "      <td>0.566908</td>\n",
       "      <td>0.128830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.280530</td>\n",
       "      <td>1.032449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.297651</td>\n",
       "      <td>1.104568</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>1.231511</td>\n",
       "      <td>1.273734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.155619</td>\n",
       "      <td>0.843453</td>\n",
       "      <td>0.616423</td>\n",
       "      <td>0.701418</td>\n",
       "      <td>0.617041</td>\n",
       "      <td>0.387897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.276092</td>\n",
       "      <td>0.994474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285093</td>\n",
       "      <td>1.087955</td>\n",
       "      <td>0.009591</td>\n",
       "      <td>1.156664</td>\n",
       "      <td>1.281061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.131758</td>\n",
       "      <td>0.837998</td>\n",
       "      <td>0.586819</td>\n",
       "      <td>0.709736</td>\n",
       "      <td>0.571892</td>\n",
       "      <td>0.349464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0.225572</td>\n",
       "      <td>1.008232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.360715</td>\n",
       "      <td>0.960098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.036021</td>\n",
       "      <td>1.318095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.109677</td>\n",
       "      <td>0.868488</td>\n",
       "      <td>0.554107</td>\n",
       "      <td>0.789290</td>\n",
       "      <td>0.381665</td>\n",
       "      <td>0.221855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.383160</td>\n",
       "      <td>0.812655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238299</td>\n",
       "      <td>0.948491</td>\n",
       "      <td>0.017939</td>\n",
       "      <td>1.009653</td>\n",
       "      <td>1.306153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.963557</td>\n",
       "      <td>0.881814</td>\n",
       "      <td>0.460020</td>\n",
       "      <td>0.666377</td>\n",
       "      <td>0.477306</td>\n",
       "      <td>0.308378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_0  feature_1  feature_2  feature_3  feature_4  feature_5   \n",
       "0     0.288854   0.862737   0.000000   0.000000   0.629075   0.049585  \\\n",
       "1     0.745873   0.750365   0.000000   0.000000   0.000000   0.000000   \n",
       "2     0.243774   1.103610   0.000000   0.403095   0.909669   0.143316   \n",
       "3     0.492079   0.310226   0.288571   0.000000   0.098349   0.315610   \n",
       "4     0.000000   0.882840   0.000000   0.008051   0.582778   0.392145   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "346   0.467792   0.817063   0.000000   0.201966   1.011639   0.000000   \n",
       "347   0.280530   1.032449   0.000000   0.297651   1.104568   0.007565   \n",
       "348   0.276092   0.994474   0.000000   0.285093   1.087955   0.009591   \n",
       "349   0.225572   1.008232   0.000000   0.360715   0.960098   0.000000   \n",
       "350   0.383160   0.812655   0.000000   0.238299   0.948491   0.017939   \n",
       "\n",
       "     feature_6  feature_7  feature_8  feature_9  feature_10  feature_11   \n",
       "0     0.764573   1.375301   0.471335   0.681091    1.029427    0.007813  \\\n",
       "1     0.000000   0.223596   0.302742   0.000000    0.400544    0.000000   \n",
       "2     1.018479   1.559943   0.000000   1.114099    1.181056    0.179748   \n",
       "3     0.000000   0.000000   0.000000   0.000000    0.000000    0.455245   \n",
       "4     0.545081   1.296126   0.912341   0.597561    1.145532    0.000000   \n",
       "..         ...        ...        ...        ...         ...         ...   \n",
       "346   1.043949   1.210953   0.000000   0.917380    0.831662    0.492514   \n",
       "347   1.231511   1.273734   0.000000   1.155619    0.843453    0.616423   \n",
       "348   1.156664   1.281061   0.000000   1.131758    0.837998    0.586819   \n",
       "349   1.036021   1.318095   0.000000   1.109677    0.868488    0.554107   \n",
       "350   1.009653   1.306153   0.000000   0.963557    0.881814    0.460020   \n",
       "\n",
       "     feature_12  feature_13  feature_14  feature_15  label  \n",
       "0      0.839820    0.000000    0.056908    0.000000      1  \n",
       "1      0.253786    0.000000    0.000000    0.376736      0  \n",
       "2      0.988379    0.178192    0.117773    0.000000      1  \n",
       "3      0.454553    0.000000    0.000000    1.703830      0  \n",
       "4      0.829006    0.000000    0.000000    0.000000      1  \n",
       "..          ...         ...         ...         ...    ...  \n",
       "346    0.604221    0.566908    0.128830    0.000000      1  \n",
       "347    0.701418    0.617041    0.387897    0.000000      1  \n",
       "348    0.709736    0.571892    0.349464    0.000000      1  \n",
       "349    0.789290    0.381665    0.221855    0.000000      1  \n",
       "350    0.666377    0.477306    0.308378    0.000000      1  \n",
       "\n",
       "[351 rows x 17 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Model(input_layer, hidden_layer)\n",
    "encoded_X = encoder.predict(X)\n",
    "new_df = pd.DataFrame(encoded_X, columns=[\"feature_{}\".format(i) for i in range(hidden_dim)])\n",
    "new_df[\"label\"] = y\n",
    "new_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
